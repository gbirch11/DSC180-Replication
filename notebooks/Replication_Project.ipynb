{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14489e80-8cfd-4d5e-a4d2-a6d8dbe0dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import spatial\n",
    "from gensim.models import word2vec\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48f9c533-0d7e-437a-8a65-a8e38b2563f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEW TESTING 12/3/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bb70540-211b-42cf-8539-7627f7f786a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt': ['atheism', 'atheists', 'religion', 'objective'],\n",
       " 'comp': ['graphics', 'windows', 'scsi', 'mac'],\n",
       " 'misc': ['sale', 'offer', 'shipping', 'forsale'],\n",
       " 'rec': ['car', 'bike', 'game', 'team'],\n",
       " 'sci': ['encryption', 'circuit', 'candida', 'space'],\n",
       " 'talk': ['turkish', 'gun', 'jews', 'armenian'],\n",
       " 'soc': ['church', 'jesus', 'christ', 'christians']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_data_coarse = pickle.load(open('data/20news/coarse/df.pkl', 'rb'))\n",
    "twenty_data_coarse.head()\n",
    "with open('data/20news/coarse/seedwords.json') as fp:\n",
    "    twenty_data_coarse_seed = json.load(fp)\n",
    "twenty_data_coarse_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7381015a-86c3-4e0f-add3-2f0444f79d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_sentences = twenty_data_coarse.sentence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a659e49-45e9-4611-b5fe-00634f01b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_words = []\n",
    "for cat in twenty_data_coarse_seed.values():\n",
    "    for word in cat:\n",
    "        seed_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be2c8f76-4f39-49b8-b418-e6dabcedce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary=seed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f12cf7c-428f-438a-a413-f970e38197da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = vectorizer.fit_transform(twenty_sentences).toarray()\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "84deb51a-a02f-467f-a59f-880c83cd35bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for doc in tfidf:\n",
    "    tfidf_vals = {}\n",
    "    idx = 0\n",
    "    for seed_cat in twenty_data_coarse_seed:\n",
    "        for seed_word in twenty_data_coarse_seed[seed_cat]:\n",
    "            try:\n",
    "                tfidf_vals[seed_cat] += doc[idx]\n",
    "            except:\n",
    "                tfidf_vals[seed_cat] = doc[idx]\n",
    "            idx += 1\n",
    "    preds.append(max(tfidf_vals, key = tfidf_vals.get))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fec849c6-eeb2-4d43-a9ad-091429ee89e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt': ['atheism', 'atheists', 'religion', 'objective'],\n",
       " 'comp': ['graphics', 'windows', 'scsi', 'mac'],\n",
       " 'misc': ['sale', 'offer', 'shipping', 'forsale'],\n",
       " 'rec': ['car', 'bike', 'game', 'team'],\n",
       " 'sci': ['encryption', 'circuit', 'candida', 'space'],\n",
       " 'talk': ['turkish', 'gun', 'jews', 'armenian'],\n",
       " 'soc': ['church', 'jesus', 'christ', 'christians']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_data_coarse_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de1182f1-b581-41f0-9070-19f0d1fcb630",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_twenty = twenty_data_coarse.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4fda3de-20be-45de-8259-70cad8bcb257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42236705186483375"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Micro F1 - 20News Coarse\n",
    "microf1_20coarse = f1_score(obs_twenty, preds, average='micro')\n",
    "microf1_20coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "866397d3-0dc7-4cb9-855d-b361c5877900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4936585127200833"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macrof1_20coarse = f1_score(obs_twenty, preds, average='macro')\n",
    "macrof1_20coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd98d4-c776-4707-8180-7ab2361ea456",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed_cat in twenty_data_coarse_seed:\n",
    "    for seed_word in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb4f7b27-c9bf-4ba5-a444-ac8bd09d22bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(vocabulary=[&#x27;atheism&#x27;, &#x27;atheists&#x27;, &#x27;religion&#x27;, &#x27;objective&#x27;,\n",
       "                            &#x27;graphics&#x27;, &#x27;windows&#x27;, &#x27;scsi&#x27;, &#x27;mac&#x27;, &#x27;sale&#x27;,\n",
       "                            &#x27;offer&#x27;, &#x27;shipping&#x27;, &#x27;forsale&#x27;, &#x27;car&#x27;, &#x27;bike&#x27;,\n",
       "                            &#x27;game&#x27;, &#x27;team&#x27;, &#x27;encryption&#x27;, &#x27;circuit&#x27;, &#x27;candida&#x27;,\n",
       "                            &#x27;space&#x27;, &#x27;turkish&#x27;, &#x27;gun&#x27;, &#x27;jews&#x27;, &#x27;armenian&#x27;,\n",
       "                            &#x27;church&#x27;, &#x27;jesus&#x27;, &#x27;christ&#x27;, &#x27;christians&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(vocabulary=[&#x27;atheism&#x27;, &#x27;atheists&#x27;, &#x27;religion&#x27;, &#x27;objective&#x27;,\n",
       "                            &#x27;graphics&#x27;, &#x27;windows&#x27;, &#x27;scsi&#x27;, &#x27;mac&#x27;, &#x27;sale&#x27;,\n",
       "                            &#x27;offer&#x27;, &#x27;shipping&#x27;, &#x27;forsale&#x27;, &#x27;car&#x27;, &#x27;bike&#x27;,\n",
       "                            &#x27;game&#x27;, &#x27;team&#x27;, &#x27;encryption&#x27;, &#x27;circuit&#x27;, &#x27;candida&#x27;,\n",
       "                            &#x27;space&#x27;, &#x27;turkish&#x27;, &#x27;gun&#x27;, &#x27;jews&#x27;, &#x27;armenian&#x27;,\n",
       "                            &#x27;church&#x27;, &#x27;jesus&#x27;, &#x27;christ&#x27;, &#x27;christians&#x27;])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(vocabulary=['atheism', 'atheists', 'religion', 'objective',\n",
       "                            'graphics', 'windows', 'scsi', 'mac', 'sale',\n",
       "                            'offer', 'shipping', 'forsale', 'car', 'bike',\n",
       "                            'game', 'team', 'encryption', 'circuit', 'candida',\n",
       "                            'space', 'turkish', 'gun', 'jews', 'armenian',\n",
       "                            'church', 'jesus', 'christ', 'christians'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5232ece7-306e-4dee-bed0-3ed22a3a27b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seeds = 0\n",
    "for seed_cat in twenty_data_coarse_seed:\n",
    "        num_seeds += len(twenty_data_coarse_seed[seed_cat])\n",
    "num_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8de17d18-55f9-476b-8525-46dc411aad85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f1b7b-b7dd-41b4-8401-2ba4ee31bada",
   "metadata": {},
   "source": [
    "## Coarse Data Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51422158-5eba-4d31-9219-8b04895212f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt': ['atheism', 'atheists', 'religion', 'objective'],\n",
       " 'comp': ['graphics', 'windows', 'scsi', 'mac'],\n",
       " 'misc': ['sale', 'offer', 'shipping', 'forsale'],\n",
       " 'rec': ['car', 'bike', 'game', 'team'],\n",
       " 'sci': ['encryption', 'circuit', 'candida', 'space'],\n",
       " 'talk': ['turkish', 'gun', 'jews', 'armenian'],\n",
       " 'soc': ['church', 'jesus', 'christ', 'christians']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_data_coarse = pickle.load(open('data/20news/coarse/df.pkl', 'rb'))\n",
    "twenty_data_coarse.head()\n",
    "with open('data/20news/coarse/seedwords.json') as fp:\n",
    "    twenty_data_coarse_seed = json.load(fp)\n",
    "twenty_data_coarse_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51f2ab8d-d368-4b71-af48-de944ec14c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>from:  (where's my thing)\\nsubject: what car i...</td>\n",
       "      <td>rec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>from:  (guy kuo)\\nsubject: si clock poll - fin...</td>\n",
       "      <td>comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>from:  (thomas e willis)\\nsubject: pb question...</td>\n",
       "      <td>comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from: jgreen@amber (joe green)\\nsubject: re: w...</td>\n",
       "      <td>comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>from:  (jonathan mcdowell)\\nsubject: re: shutt...</td>\n",
       "      <td>sci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18254</th>\n",
       "      <td>from:  (stupendous man)\\nsubject: re: temperat...</td>\n",
       "      <td>sci</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18255</th>\n",
       "      <td>from:  (jim smyton)\\nsubject: re: monitors - s...</td>\n",
       "      <td>comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18256</th>\n",
       "      <td>from: \\nsubject: re: game length (was re: brav...</td>\n",
       "      <td>rec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18257</th>\n",
       "      <td>from:  \\nsubject: intel chmos 8086/8088 design...</td>\n",
       "      <td>misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18258</th>\n",
       "      <td>from: \\nsubject: re: homosexuality issues in c...</td>\n",
       "      <td>soc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18259 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence label\n",
       "0      from:  (where's my thing)\\nsubject: what car i...   rec\n",
       "1      from:  (guy kuo)\\nsubject: si clock poll - fin...  comp\n",
       "2      from:  (thomas e willis)\\nsubject: pb question...  comp\n",
       "3      from: jgreen@amber (joe green)\\nsubject: re: w...  comp\n",
       "4      from:  (jonathan mcdowell)\\nsubject: re: shutt...   sci\n",
       "...                                                  ...   ...\n",
       "18254  from:  (stupendous man)\\nsubject: re: temperat...   sci\n",
       "18255  from:  (jim smyton)\\nsubject: re: monitors - s...  comp\n",
       "18256  from: \\nsubject: re: game length (was re: brav...   rec\n",
       "18257  from:  \\nsubject: intel chmos 8086/8088 design...  misc\n",
       "18258  from: \\nsubject: re: homosexuality issues in c...   soc\n",
       "\n",
       "[18259 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_data_coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e31748c8-b32d-40b2-95e8-e0589d701950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arts': ['music', 'orchestra', 'album', 'opera', 'ballet'],\n",
       " 'business': ['companies', 'euro', 'economy', 'batteries', 'sales'],\n",
       " 'science': ['space', 'researchers', 'scientists', 'research', 'science'],\n",
       " 'sports': ['yankees', 'cup', 'league', 'basketball', 'golf'],\n",
       " 'politics': ['republicans', 'senator', 'senate', 'democrats', 'election']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_data_coarse = pickle.load(open('data/nyt/coarse/df.pkl', 'rb'))\n",
    "nyt_data_coarse.head()\n",
    "with open('data/nyt/coarse/seedwords.json') as fp:\n",
    "    nyt_data_coarse_seed = json.load(fp)\n",
    "nyt_data_coarse_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04eb32f3-ee3d-4fdd-8e59-373fa04d680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docFreq_twenty = {}\n",
    "docFreq_nyt = {}\n",
    "twenty_sentences = twenty_data_coarse.sentence.values\n",
    "nyt_sentences = nyt_data_coarse.sentence.values\n",
    "#twenty_sentences[0], nyt_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5d0dee-8193-47d3-9820-deb8b647db89",
   "metadata": {},
   "source": [
    "Example of a document in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "259a64a4-e35a-453c-903d-93d2492d5fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from:  (where's my thing)\\nsubject: what car is this!?\\nnntp-posting-host: rac3.wam.umd.edu\\norganization: university of maryland, college park\\nlines: 15\\n\\n i was wondering if anyone out there could enlighten me on this car i saw\\nthe other day. it was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. it was called a bricklin. the doors were really small. in addition,\\nthe front bumper was separate from the rest of the body. this is \\nall i know. if anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nthanks,\\n- il\\n   ---- brought to you by your neighborhood lerxst ----\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6826ae1c-f555-4af4-973f-bae0cddb7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in twenty_sentences:\n",
    "    words = sentence.strip().split()\n",
    "    temp_set = set(words)\n",
    "    for c in temp_set:\n",
    "        try:\n",
    "            docFreq_twenty[c] += 1\n",
    "        except:\n",
    "            docFreq_twenty[c] = 1\n",
    "\n",
    "for sentence in nyt_sentences:\n",
    "    words = sentence.strip().split()\n",
    "    temp_set = set(words)\n",
    "    for c in temp_set:\n",
    "        try:\n",
    "            docFreq_nyt[c] += 1\n",
    "        except:\n",
    "            docFreq_nyt[c] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "995f0aeb-5443-4b9e-af9f-c1caef5b41b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_docFreq_twenty = {}\n",
    "inv_docFreq_nyt = {}\n",
    "twenty_N = len(twenty_data_coarse)\n",
    "nyt_N = len(nyt_data_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fc7a5af-e890-4978-a55a-140ad4c34b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in docFreq_twenty:\n",
    "    inv_docFreq_twenty[word] = np.log(twenty_N / docFreq_twenty[word])\n",
    "for word in docFreq_nyt:\n",
    "    inv_docFreq_nyt[word] = np.log(nyt_N / docFreq_nyt[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "447c1ec6-80b6-4915-b0e0-130a51b00aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"TESTING CELL\\npreds = []\\nfor doc in twenty_sentences[1:5]:\\n    words = doc.strip().split()\\n    tf = {}\\n    temp_set = set(words)\\n    for c in temp_set:\\n        try:\\n            tf[c] += 1\\n        except:\\n            tf[c] = 1\\n    print(tf)\\n    tf = {k: v / total for total in (sum(tf.values()),) for k,v in tf.items()}\\n    \\n    tfidf = {}\\n    for seed_cat in twenty_data_coarse_seed:\\n        for seed_word in twenty_data_coarse_seed[seed_cat]:\\n            if seed_word in tf:\\n                #print('yes', seed_word)\\n                try:\\n                    tfidf[seed_cat] += tf[seed_word] * inv_docFreq_twenty[seed_word]\\n                except:\\n                    tfidf[seed_cat] = tf[seed_word] * inv_docFreq_twenty[seed_word]\\n            else:\\n                try:\\n                    tfidf[seed_cat] += 0\\n                except:\\n                    tfidf[seed_cat] = 0\\n    print(max(tfidf.values()))\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''TESTING CELL\n",
    "preds = []\n",
    "for doc in twenty_sentences[1:5]:\n",
    "    words = doc.strip().split()\n",
    "    tf = {}\n",
    "    temp_set = set(words)\n",
    "    for c in temp_set:\n",
    "        try:\n",
    "            tf[c] += 1\n",
    "        except:\n",
    "            tf[c] = 1\n",
    "    print(tf)\n",
    "    tf = {k: v / total for total in (sum(tf.values()),) for k,v in tf.items()}\n",
    "    \n",
    "    tfidf = {}\n",
    "    for seed_cat in twenty_data_coarse_seed:\n",
    "        for seed_word in twenty_data_coarse_seed[seed_cat]:\n",
    "            if seed_word in tf:\n",
    "                #print('yes', seed_word)\n",
    "                try:\n",
    "                    tfidf[seed_cat] += tf[seed_word] * inv_docFreq_twenty[seed_word]\n",
    "                except:\n",
    "                    tfidf[seed_cat] = tf[seed_word] * inv_docFreq_twenty[seed_word]\n",
    "            else:\n",
    "                try:\n",
    "                    tfidf[seed_cat] += 0\n",
    "                except:\n",
    "                    tfidf[seed_cat] = 0\n",
    "    print(max(tfidf.values()))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce2db0d1-d9b7-4d7e-b7f4-71c8797ca09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt',\n",
       " 'talk',\n",
       " 'comp',\n",
       " 'alt',\n",
       " 'talk',\n",
       " 'alt',\n",
       " 'rec',\n",
       " 'rec',\n",
       " 'alt',\n",
       " 'alt',\n",
       " 'alt',\n",
       " 'alt',\n",
       " 'misc',\n",
       " 'rec',\n",
       " 'alt']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_twenty = []\n",
    "for doc in twenty_sentences:\n",
    "    words = doc.strip().split()\n",
    "    tf = {}\n",
    "    temp_set = set(words)\n",
    "    for c in temp_set:\n",
    "        try:\n",
    "            tf[c] += 1\n",
    "        except:\n",
    "            tf[c] = 1\n",
    "    ## Not sure if I need to divide here (recall Professor saying we are just \"counting\")\n",
    "    #tf = {k: v / total for total in (sum(tf.values()),) for k,v in tf.items()}\n",
    "    \n",
    "    tfidf = {}\n",
    "    for seed_cat in twenty_data_coarse_seed:\n",
    "        for seed_word in twenty_data_coarse_seed[seed_cat]:\n",
    "            if seed_word in tf:\n",
    "\n",
    "                try:\n",
    "                    tfidf[seed_cat] += tf[seed_word] * inv_docFreq_twenty[seed_word]\n",
    "                except:\n",
    "                    tfidf[seed_cat] = tf[seed_word] * inv_docFreq_twenty[seed_word]\n",
    "            else:\n",
    "                try:\n",
    "                    tfidf[seed_cat] += 0\n",
    "                except:\n",
    "                    tfidf[seed_cat] = 0\n",
    "    preds_twenty.append(max(tfidf, key=tfidf.get))\n",
    "preds_twenty[50:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bdb696e-5bf0-47cd-ac3b-391dadca1bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['comp', 'soc', 'comp', 'sci', 'talk', 'sci', 'rec', 'rec', 'comp',\n",
       "       'sci', 'sci', 'comp', 'misc', 'rec', 'alt'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_twenty = twenty_data_coarse.label.values\n",
    "obs_twenty[50:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ae3545c-3082-4c0f-aac2-e9554d71186b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.349361958486226"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Micro F1 - 20News Coarse\n",
    "microf1_20coarse = f1_score(obs_twenty, preds_twenty, average='micro')\n",
    "microf1_20coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59d53ebf-8b89-4c54-8d52-cbfe99895178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4271360334016361"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Macro F1 - 20News Coarse\n",
    "macrof1_20coarse = f1_score(obs_twenty, preds_twenty, average='macro')\n",
    "macrof1_20coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "752982c9-4673-4942-b706-d78cc29cf0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arts',\n",
       " 'sports',\n",
       " 'arts',\n",
       " 'sports',\n",
       " 'sports',\n",
       " 'arts',\n",
       " 'business',\n",
       " 'arts',\n",
       " 'sports',\n",
       " 'arts',\n",
       " 'sports',\n",
       " 'arts',\n",
       " 'science',\n",
       " 'sports',\n",
       " 'sports']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_nyt = []\n",
    "for doc in nyt_sentences:\n",
    "    words = doc.strip().split()\n",
    "    tf = {}\n",
    "    temp_set = set(words)\n",
    "    for c in temp_set:\n",
    "        try:\n",
    "            tf[c] += 1\n",
    "        except:\n",
    "            tf[c] = 1\n",
    "    ## Not sure if I need to divide here.\n",
    "    #tf = {k: v / total for total in (sum(tf.values()),) for k,v in tf.items()}\n",
    "    \n",
    "    tfidf = {}\n",
    "    for seed_cat in nyt_data_coarse_seed:\n",
    "        for seed_word in nyt_data_coarse_seed[seed_cat]:\n",
    "            if seed_word in tf:\n",
    "                try:\n",
    "                    tfidf[seed_cat] += tf[seed_word] * inv_docFreq_nyt[seed_word]\n",
    "                except:\n",
    "                    tfidf[seed_cat] = tf[seed_word] * inv_docFreq_nyt[seed_word]\n",
    "            else:\n",
    "                try:\n",
    "                    tfidf[seed_cat] += 0\n",
    "                except:\n",
    "                    tfidf[seed_cat] = 0\n",
    "    preds_nyt.append(max(tfidf, key=tfidf.get))\n",
    "preds_nyt[50:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14e0f4f5-3b80-428d-a5df-678efdeb4108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sports', 'sports', 'arts', 'sports', 'sports', 'sports',\n",
       "       'business', 'sports', 'sports', 'sports', 'sports', 'sports',\n",
       "       'science', 'sports', 'sports'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_nyt = nyt_data_coarse.label.values\n",
    "obs_nyt[50:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a22cc08e-434c-4abc-9f47-e2d4f16dab8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5957317602151471"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Micro F1 - NYT Coarse\n",
    "microf1_NYTcoarse = f1_score(obs_nyt, preds_nyt, average='micro')\n",
    "microf1_NYTcoarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06bb0ba8-a7e6-46c7-a151-bdd2a4f5ec0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47609478030530916"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Macro F1 - NYT Coarse\n",
    "macrof1_NYTcoarse = f1_score(obs_nyt, preds_nyt, average='macro')\n",
    "macrof1_NYTcoarse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26542fff-fc1a-415f-99b3-757344b5bb11",
   "metadata": {},
   "source": [
    "## Fine-Grained Data Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06f5a953-5938-465d-a512-d59b4e830529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': ['atheism', 'atheists', 'rushdie'],\n",
       " 'comp.graphics': ['jpeg', 'gif', 'images', 'graphics'],\n",
       " 'comp.os.ms-windows.misc': ['driver', 'microsoft', 'dos', 'windows'],\n",
       " 'comp.sys.ibm.pc.hardware': ['scsi', 'ide', 'controller', 'drive'],\n",
       " 'comp.sys.mac.hardware': ['apple', 'mac', 'centris', 'powerbook'],\n",
       " 'comp.windows.x': ['motif', 'x11r5', 'xterm', 'window'],\n",
       " 'misc.forsale': ['sale', 'offer', 'shipping', 'forsale'],\n",
       " 'rec.autos': ['car', 'mustang'],\n",
       " 'rec.motorcycles': ['bike', 'dod', 'bikes'],\n",
       " 'rec.sport.baseball': ['baseball'],\n",
       " 'rec.sport.hockey': ['hockey', 'nhl'],\n",
       " 'sci.crypt': ['encryption', 'clipper', 'key', 'chip'],\n",
       " 'sci.electronics': ['circuit', 'current', 'wire', 'voltage'],\n",
       " 'sci.med': ['candida', 'msg', 'vitamin'],\n",
       " 'sci.space': ['space', 'shuttle', 'orbit'],\n",
       " 'soc.religion.christian': ['jesus', 'christ', 'church', 'bible'],\n",
       " 'talk.politics.guns': ['weapons', 'gun', 'guns', 'firearms'],\n",
       " 'talk.politics.mideast': ['armenian', 'israeli', 'turkish', 'arab'],\n",
       " 'talk.politics.misc': ['stephanopoulos', 'cramer', 'clayton', 'gay'],\n",
       " 'talk.religion.misc': ['weiss', 'malcolm', 'sandvik', 'jehovah']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_data_fine = pickle.load(open('data/20news/fine/df.pkl', 'rb'))\n",
    "twenty_data_fine.head()\n",
    "with open('data/20news/fine/seedwords.json') as fp:\n",
    "    twenty_data_fine_seed = json.load(fp)\n",
    "twenty_data_fine_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7a3c46c-ca56-46f5-93b4-72b270b1e471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'federal_budget': ['cuts', 'budget', 'debt'],\n",
       " 'gun_control': ['guns', 'weapons', 'firearms'],\n",
       " 'law_enforcement': ['death', 'judge', 'prosecutors'],\n",
       " 'gay_rights': ['gay', 'marriage', 'same-sex'],\n",
       " 'energy_companies': ['energy', 'oil', 'gas'],\n",
       " 'environment': ['climate', 'fish', 'wildlife', 'carbon'],\n",
       " 'immigration': ['immigration', 'immigrants', 'citizenship'],\n",
       " 'military': ['military', 'pentagon', 'army', 'marine'],\n",
       " 'cosmos': ['spacecraft', 'sun', 'kepler'],\n",
       " 'the_affordable_care_act': ['medicaid', 'coverage', 'insurance'],\n",
       " 'stocks_and_bonds': ['earnings', 'stocks', 'investors'],\n",
       " 'international_business': ['bank', 'european', 'china'],\n",
       " 'abortion': ['abortion'],\n",
       " 'music': ['music'],\n",
       " 'baseball': ['baseball'],\n",
       " 'economy': ['economy'],\n",
       " 'television': ['episode', 'episodes', 'viewers'],\n",
       " 'golf': ['golf'],\n",
       " 'tennis': ['tennis'],\n",
       " 'hockey': ['hockey'],\n",
       " 'football': ['football'],\n",
       " 'dance': ['dance'],\n",
       " 'movies': ['movies'],\n",
       " 'soccer': ['soccer'],\n",
       " 'surveillance': ['surveillance', 'intelligence', 'snowden'],\n",
       " 'basketball': ['basketball']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_data_fine = pickle.load(open('data/nyt/fine/df.pkl', 'rb'))\n",
    "nyt_data_fine.head()\n",
    "with open('data/nyt/fine/seedwords.json') as fp:\n",
    "    nyt_data_fine_seed = json.load(fp)\n",
    "nyt_data_fine_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79e803ae-d885-4f10-8b91-5d07a4134aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "docFreq_twenty = {}\n",
    "docFreq_nyt = {}\n",
    "twenty_sentences = twenty_data_fine.sentence.values\n",
    "nyt_sentences = nyt_data_fine.sentence.values\n",
    "#twenty_sentences[0], nyt_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b0a2de0-7ef5-4ff9-a156-c8111602d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in twenty_sentences:\n",
    "    words = sentence.strip().split()\n",
    "    temp_set = set(words)\n",
    "    for c in temp_set:\n",
    "        try:\n",
    "            docFreq_twenty[c] += 1\n",
    "        except:\n",
    "            docFreq_twenty[c] = 1\n",
    "\n",
    "for sentence in nyt_sentences:\n",
    "    words = sentence.strip().split()\n",
    "    temp_set = set(words)\n",
    "    for c in temp_set:\n",
    "        try:\n",
    "            docFreq_nyt[c] += 1\n",
    "        except:\n",
    "            docFreq_nyt[c] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32de261d-d019-4c6f-b3a4-541c19a57b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_docFreq_twenty = {}\n",
    "inv_docFreq_nyt = {}\n",
    "twenty_N = len(twenty_data_coarse)\n",
    "nyt_N = len(nyt_data_coarse)\n",
    "\n",
    "for word in docFreq_twenty:\n",
    "    inv_docFreq_twenty[word] = np.log(twenty_N / docFreq_twenty[word])\n",
    "for word in docFreq_nyt:\n",
    "    inv_docFreq_nyt[word] = np.log(nyt_N / docFreq_nyt[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc3a04ed-f244-4b7b-af76-f6100ebb8e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sci.electronics',\n",
       " 'alt.atheism',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'alt.atheism',\n",
       " 'talk.politics.mideast',\n",
       " 'sci.crypt',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'alt.atheism',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'sci.space',\n",
       " 'alt.atheism',\n",
       " 'alt.atheism',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'alt.atheism']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_twenty_fine = []\n",
    "for doc in twenty_sentences:\n",
    "    words = doc.strip().split()\n",
    "    tf = {}\n",
    "    temp_set = set(words)\n",
    "    for c in temp_set:\n",
    "        try:\n",
    "            tf[c] += 1\n",
    "        except:\n",
    "            tf[c] = 1\n",
    "    ## Not sure if I need to divide here (recall Professor saying we are just \"counting\")\n",
    "    #tf = {k: v / total for total in (sum(tf.values()),) for k,v in tf.items()}\n",
    "    \n",
    "    tfidf = {}\n",
    "    for seed_cat in twenty_data_fine_seed:\n",
    "        for seed_word in twenty_data_fine_seed[seed_cat]:\n",
    "            if seed_word in tf:\n",
    "\n",
    "                try:\n",
    "                    tfidf[seed_cat] += tf[seed_word] * inv_docFreq_twenty[seed_word]\n",
    "                except:\n",
    "                    tfidf[seed_cat] = tf[seed_word] * inv_docFreq_twenty[seed_word]\n",
    "            else:\n",
    "                try:\n",
    "                    tfidf[seed_cat] += 0\n",
    "                except:\n",
    "                    tfidf[seed_cat] = 0\n",
    "    preds_twenty_fine.append(max(tfidf, key=tfidf.get))\n",
    "preds_twenty_fine[50:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75ba5b69-e13d-46a1-a9fe-7fa66dcb9260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['comp.windows.x', 'soc.religion.christian',\n",
       "       'comp.os.ms-windows.misc', 'sci.med', 'talk.politics.mideast',\n",
       "       'sci.crypt', 'rec.autos', 'rec.sport.hockey',\n",
       "       'comp.os.ms-windows.misc', 'sci.space', 'sci.electronics',\n",
       "       'comp.sys.mac.hardware', 'misc.forsale', 'rec.autos',\n",
       "       'alt.atheism'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_twenty_fine = twenty_data_fine.label.values\n",
    "obs_twenty_fine[50:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "870aea24-02af-4b52-9029-f08e1d849833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42521496248425433"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Micro F1 - 20News Fine\n",
    "microf1_20fine = f1_score(obs_twenty_fine, preds_twenty_fine, average='micro')\n",
    "microf1_20fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0f25476-34ba-4a78-8b93-21983e29883a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47387491770069035"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Macro F1 - 20News Fine\n",
    "macrof1_20fine = f1_score(obs_twenty_fine, preds_twenty_fine, average='macro')\n",
    "macrof1_20fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bc1fbdc-baaf-4080-b07b-cf867bb31d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['football',\n",
       " 'soccer',\n",
       " 'environment',\n",
       " 'football',\n",
       " 'soccer',\n",
       " 'federal_budget',\n",
       " 'federal_budget',\n",
       " 'federal_budget',\n",
       " 'federal_budget',\n",
       " 'federal_budget',\n",
       " 'international_business',\n",
       " 'federal_budget',\n",
       " 'federal_budget',\n",
       " 'international_business',\n",
       " 'basketball']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_nyt_fine = []\n",
    "for doc in nyt_sentences:\n",
    "    words = doc.strip().split()\n",
    "    tf = {}\n",
    "    temp_set = set(words)\n",
    "    for c in temp_set:\n",
    "        try:\n",
    "            tf[c] += 1\n",
    "        except:\n",
    "            tf[c] = 1\n",
    "    ## Not sure if I need to divide here (recall Professor saying we are just \"counting\")\n",
    "    #tf = {k: v / total for total in (sum(tf.values()),) for k,v in tf.items()}\n",
    "    \n",
    "    tfidf = {}\n",
    "    for seed_cat in nyt_data_fine_seed:\n",
    "        for seed_word in nyt_data_fine_seed[seed_cat]:\n",
    "            if seed_word in tf:\n",
    "\n",
    "                try:\n",
    "                    tfidf[seed_cat] += tf[seed_word] * inv_docFreq_nyt[seed_word]\n",
    "                except:\n",
    "                    tfidf[seed_cat] = tf[seed_word] * inv_docFreq_nyt[seed_word]\n",
    "            else:\n",
    "                try:\n",
    "                    tfidf[seed_cat] += 0\n",
    "                except:\n",
    "                    tfidf[seed_cat] = 0\n",
    "    preds_nyt_fine.append(max(tfidf, key=tfidf.get))\n",
    "preds_nyt_fine[50:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f0e4993-560b-4d5f-9e5f-ad16caff9494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['soccer', 'soccer', 'music', 'soccer', 'soccer', 'tennis',\n",
       "       'international_business', 'golf', 'soccer', 'soccer', 'golf',\n",
       "       'tennis', 'cosmos', 'soccer', 'basketball'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_nyt_fine = nyt_data_fine.label.values\n",
    "obs_nyt_fine[50:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76f85ddc-e7d8-4a7e-a353-35b9f3731132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37295046412770017"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Micro F1 - NYT Fine\n",
    "microf1_NYTfine = f1_score(obs_nyt_fine, preds_nyt_fine, average='micro')\n",
    "microf1_NYTfine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afb7665f-b352-46a5-9655-758894732214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4368571787265614"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Macro F1 - NYT Fine\n",
    "macrof1_NYTfine = f1_score(obs_nyt_fine, preds_nyt_fine, average='macro')\n",
    "macrof1_NYTfine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474b909-fd98-4118-8a31-e00379fc39af",
   "metadata": {},
   "source": [
    "## Results TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb1a2768-d7db-414c-b1d2-dda5ce295abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>grained</th>\n",
       "      <th>f1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">20News</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Coarse</th>\n",
       "      <th>Macro</th>\n",
       "      <td>0.427136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.349362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fine</th>\n",
       "      <th>Macro</th>\n",
       "      <td>0.473875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.425215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">NYT</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Coarse</th>\n",
       "      <th>Macro</th>\n",
       "      <td>0.476095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.595732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fine</th>\n",
       "      <th>Macro</th>\n",
       "      <td>0.436857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro</th>\n",
       "      <td>0.372950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          score\n",
       "dataset grained f1             \n",
       "20News  Coarse  Macro  0.427136\n",
       "                Micro  0.349362\n",
       "        Fine    Macro  0.473875\n",
       "                Micro  0.425215\n",
       "NYT     Coarse  Macro  0.476095\n",
       "                Micro  0.595732\n",
       "        Fine    Macro  0.436857\n",
       "                Micro  0.372950"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns=['dataset', 'grained', 'f1', 'score'], data = [['20News', 'Fine', 'Micro', microf1_20fine], ['20News', 'Fine', 'Macro', macrof1_20fine],['20News', 'Coarse', 'Micro', microf1_20coarse],\n",
    "                                                                           ['20News', 'Coarse', 'Macro', macrof1_20coarse],['NYT', 'Fine', 'Micro', microf1_NYTfine],['NYT', 'Fine', 'Macro', macrof1_NYTfine],\n",
    "                                                                           ['NYT', 'Coarse', 'Micro', microf1_NYTcoarse],['NYT', 'Coarse', 'Macro', macrof1_NYTcoarse],])\n",
    "results.groupby(['dataset', 'grained', 'f1']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1d5efb-f22b-4de5-9b6d-db451fbb343d",
   "metadata": {},
   "source": [
    "## Overall Thoughts and Conclusions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df48043-14a3-4aab-a4a5-161385accbaa",
   "metadata": {},
   "source": [
    "Both Micro and Macro F1 Scores slightly lower than expected. Maybe due to the preprocessing and tokenization done in the ConWea paper's setting?\n",
    "<br>\n",
    "Also done without packages, maybe my math is flawed. Double check this one more time. TF-IDF should be that straight forward though.\n",
    "<br>\n",
    "Extra Note: Interesting how my Macro-F1 for 20News is higher than the Micro. It is opposite in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d9109-6344-4fe8-a617-d353b32e1ebd",
   "metadata": {},
   "source": [
    "## TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d363b6-b0b3-4570-8bfd-fcfb493845d7",
   "metadata": {},
   "source": [
    "1) Finish TFIDF with Fine Grained Data (Easy) ** DONE (Still look into method, maybe do some preprocesing to help accuracy)\n",
    "2) Work on Word2Vec using Gensim package\n",
    "3) Finish Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf145669-bbaa-4a53-9d41-5c691992bb15",
   "metadata": {},
   "source": [
    "## Word2Vec Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34d08b0f-1bc3-4665-bff4-1363361bcd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMINDERS\n",
    "## Don't loop through dict, it can be random order\n",
    "## Change min_count, other hyperparams to mess with results\n",
    "## Jingbo said to put in the effort and you'll do fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad3ad051-e526-4ec5-a72a-1f4808dd73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2faf4f2",
   "metadata": {},
   "source": [
    "## Coarse - 20News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc66b46a-303a-45eb-b613-050161001e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt': ['atheism', 'atheists', 'religion', 'objective'],\n",
       " 'comp': ['graphics', 'windows', 'scsi', 'mac'],\n",
       " 'misc': ['sale', 'offer', 'shipping', 'forsale'],\n",
       " 'rec': ['car', 'bike', 'game', 'team'],\n",
       " 'sci': ['encryption', 'circuit', 'candida', 'space'],\n",
       " 'talk': ['turkish', 'gun', 'jews', 'armenian'],\n",
       " 'soc': ['church', 'jesus', 'christ', 'christians']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_data_coarse = pickle.load(open('data/20news/coarse/df.pkl', 'rb'))\n",
    "twenty_data_coarse.head()\n",
    "\n",
    "with open('data/20news/coarse/seedwords.json') as fp:\n",
    "    twenty_data_coarse_seed = json.load(fp)\n",
    "twenty_data_coarse_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fd351a4-1c3e-44f9-a3b0-2cf7eae0bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_sentences = twenty_data_coarse.sentence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5eea7ae-6cb0-4431-a313-63aec3a7acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6c2161f-705d-4bd4-931c-375cb52ec347",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TfidfVectorizer().build_tokenizer()\n",
    "punctuation = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83fd55c1-856d-4a03-a98e-c8a97da94e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = Tokenizer(num_words=150000, filters='!\"#%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e86a4117-d122-4e0b-8236-ba8188432619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.fit_on_texts(twenty_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2df6955-f8f0-423b-9339-0a1a665ff8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac85990d-7049-4c83-bc16-0e1d354e4e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for sentence in twenty_sentences:\n",
    "    sentence = sentence.lower()\n",
    "    sentence = [i for i in sentence if not (i in punctuation)]\n",
    "    sentence = ''.join(sentence)\n",
    "    currWords = tokenizer(sentence)\n",
    "    currWords = [w for w in currWords if w not in stop_words]\n",
    "    words.append(currWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af56c42-5eef-4806-b46c-c488d3546e67",
   "metadata": {},
   "source": [
    "Be careful with workers param, tuned on CPU = AMD RYZEN 5900X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88b72312-b8d6-4962-a96d-d71da40c52e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(words, workers=24, min_count=5, window=5, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e43f91e0-ad38-46e3-b244-8416a32df2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = twenty_data_coarse.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9970ea1-cca4-4f39-a193-821f67d3d326",
   "metadata": {},
   "source": [
    "Concatenate all seed weights for each category into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5569d6d-87fe-4b08-b4ad-8e6ae6641604",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_weights = {}\n",
    "for seed_cat in twenty_data_coarse_seed:\n",
    "    for seed_word in twenty_data_coarse_seed[seed_cat]:\n",
    "        if seed_word in model.wv:\n",
    "            try:\n",
    "                seed_weights[seed_cat] += model.wv[seed_word]\n",
    "            except:\n",
    "                seed_weights[seed_cat] = model.wv[seed_word]\n",
    "    seed_weights[seed_cat] = seed_weights[seed_cat] / len(twenty_data_coarse_seed[seed_cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e40b6dd-c70e-456c-8404-b6e3808f1ffb",
   "metadata": {},
   "source": [
    "Concatenate each word in a documents weights to get full document weights (vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93e07654-94f5-4f6a-a233-f446034bb3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "doc_weights = []\n",
    "for sentence in words:\n",
    "    cnt = 0\n",
    "    doc_w = None\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            cnt += 1\n",
    "            if doc_w is None:\n",
    "                doc_w = copy(model.wv[word])\n",
    "            else:\n",
    "                doc_w += model.wv[word]\n",
    "    doc_weights.append(doc_w / cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d207102-648a-4e1b-a7d7-84fcbcb176e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for doc, val in enumerate(doc_weights):\n",
    "    sim = -10\n",
    "    pred = 'N/A'\n",
    "    for seed, seed_val in seed_weights.items():\n",
    "        currSim = 1 - spatial.distance.cosine(val, seed_val)\n",
    "        #print(currSim, seed)\n",
    "        if currSim > sim:\n",
    "            #print(sim, seed)\n",
    "            sim = currSim\n",
    "            pred = seed\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "efa7f3cd-35ef-4e6a-a888-dd32976d9ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33801458372047793"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37d3039a-3ecb-4632-82e0-9a3c4b29fc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3798126951092612"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, preds, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c79c62",
   "metadata": {},
   "source": [
    "## Coarse - NYT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a92ced5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for sentence in nyt_sentences:\n",
    "    sentence = sentence.lower()\n",
    "    #sentence = [i for i in sentence if not (i in punctuation)]\n",
    "    #sentence = ''.join(sentence)\n",
    "    currWords = tokenizer(sentence)\n",
    "    currWords = [w for w in currWords if w not in stop_words]\n",
    "    words.append(currWords)\n",
    "\n",
    "#for seed_cat in twenty_data_coarse_seed:\n",
    " #   for seed_word in twenty_data_coarse_seed[seed_cat]:\n",
    " #      words.append(seed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db502524",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(words, workers=15, min_count=2, window=5, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0dad653f-ce83-4631-b0f6-ce68ff17e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(words, vector_size = 500, workers=24, min_count=5, window=5, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "812611d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_weights = {}\n",
    "for sentence in words:\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            word_weights[word] = model.wv[word]\n",
    "        except:\n",
    "            word_weights[word] = np.random.uniform(-0.25, 0.25, model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05e140be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = nyt_data_coarse.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "be7b4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_weights = {}\n",
    "for seed_cat in nyt_data_coarse_seed:\n",
    "    for seed_word in nyt_data_coarse_seed[seed_cat]:\n",
    "        try:\n",
    "            seed_weights[seed_cat] += model.wv[seed_word]\n",
    "        except:\n",
    "            seed_weights[seed_cat] = model.wv[seed_word]\n",
    "    seed_weights[seed_cat] = seed_weights[seed_cat] / len(nyt_data_coarse_seed[seed_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e9606967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "doc_weights = []\n",
    "for sentence in words:\n",
    "    cnt = 0\n",
    "    doc_w = None\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            cnt += 1\n",
    "            if doc_w is None:\n",
    "                doc_w = copy(model.wv[word])\n",
    "            else:\n",
    "                doc_w += model.wv[word]\n",
    "    doc_weights.append(doc_w / cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "abc09eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for doc, val in enumerate(doc_weights):\n",
    "    sim = -10\n",
    "    pred = 'N/A'\n",
    "    for seed, seed_val in seed_weights.items():\n",
    "        currSim = 1 - spatial.distance.cosine(val, seed_val)\n",
    "        #print(currSim, seed)\n",
    "        if currSim > sim:\n",
    "            #print(sim, seed)\n",
    "            sim = currSim\n",
    "            pred = seed\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b27e4fc-ed63-47aa-9146-748368d7437a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47801887686590466"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0712da7f-4505-4c82-bdc2-4e8bb2205cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715277175327492"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, preds, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e30f94b",
   "metadata": {},
   "source": [
    "## Fine - 20News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3899bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_data_fine = pickle.load(open('data/20news/fine/df.pkl', 'rb'))\n",
    "twenty_data_fine.head()\n",
    "with open('data/20news/fine/seedwords.json') as fp:\n",
    "    twenty_data_fine_seed = json.load(fp)\n",
    "twenty_sentences = twenty_data_fine.sentence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a3856f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for sentence in twenty_sentences:\n",
    "    sentence = sentence.lower()\n",
    "    sentence = [i for i in sentence if not (i in punctuation)]\n",
    "    sentence = ''.join(sentence)\n",
    "    currWords = tokenizer(sentence)\n",
    "    currWords = [w for w in currWords if w not in stop_words]\n",
    "    words.append(currWords)\n",
    "\n",
    "for seed_cat in twenty_data_fine_seed:\n",
    "    for seed_word in twenty_data_fine_seed[seed_cat]:\n",
    "        words.append(seed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e2c86c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(words, workers=15, min_count=2, window=5, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "edfb4b73-8411-4fb3-ad71-1aabb101f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(words, vector_size = 500, workers=24, min_count=5, window=5, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf3d1478",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_weights = {}\n",
    "for sentence in words:\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            word_weights[word] = model.wv[word]\n",
    "        except:\n",
    "            word_weights[word] = np.random.uniform(-0.25, 0.25, model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb73304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = twenty_data_fine.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb6a9142",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_weights = {}\n",
    "for seed_cat in twenty_data_fine_seed:\n",
    "    for seed_word in twenty_data_fine_seed[seed_cat]:\n",
    "        try:\n",
    "            seed_weights[seed_cat] += model.wv[seed_word]\n",
    "        except:\n",
    "            seed_weights[seed_cat] = model.wv[seed_word]\n",
    "    seed_weights[seed_cat] = seed_weights[seed_cat] / len(twenty_data_fine_seed[seed_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f8f4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "doc_weights = []\n",
    "for sentence in words:\n",
    "    cnt = 0\n",
    "    doc_w = None\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            cnt += 1\n",
    "            if doc_w is None:\n",
    "                doc_w = copy(model.wv[word])\n",
    "            else:\n",
    "                doc_w += model.wv[word]\n",
    "    doc_weights.append(doc_w / cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36a9d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for doc, val in enumerate(doc_weights):\n",
    "    sim = -10\n",
    "    pred = 'N/A'\n",
    "    for seed, seed_val in seed_weights.items():\n",
    "        currSim = 1 - spatial.distance.cosine(val, seed_val)\n",
    "        #print(currSim, seed)\n",
    "        if currSim > sim:\n",
    "            #print(sim, seed)\n",
    "            sim = currSim\n",
    "            pred = seed\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e5f7567",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_size = 0\n",
    "for seed_cat in twenty_data_fine_seed:\n",
    "    for seed_word in twenty_data_fine_seed[seed_cat]:\n",
    "        seed_size+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d960180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds[:len(doc_weights)-seed_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b5c23302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2850594482539313"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f74e0342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30981981488580973"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, preds, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59540b41-ac49-4b69-a093-3707fbefd501",
   "metadata": {},
   "source": [
    "## Fine - NYT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11488958-e50b-44d8-aa0a-9c9dceb7908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_data_fine = pickle.load(open('data/nyt/fine/df.pkl', 'rb'))\n",
    "nyt_data_fine.head()\n",
    "with open('data/nyt/fine/seedwords.json') as fp:\n",
    "    nyt_data_fine_seed = json.load(fp)\n",
    "nyt_sentences = nyt_data_fine.sentence.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c6346d8a-39a4-44c9-bcb5-2043dac9af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for sentence in nyt_sentences:\n",
    "    sentence = sentence.lower()\n",
    "    #sentence = [i for i in sentence if not (i in punctuation)]\n",
    "    #sentence = ''.join(sentence)\n",
    "    currWords = tokenizer(sentence)\n",
    "    currWords = [w for w in currWords if w not in stop_words]\n",
    "    words.append(currWords)\n",
    "\n",
    "for seed_cat in nyt_data_fine_seed:\n",
    "    for seed_word in nyt_data_fine_seed[seed_cat]:\n",
    "        #print(seed_word)\n",
    "        words.append(seed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0fb2ba0d-6cec-470f-bad0-b0e2407df2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(words, vector_size = 500, workers=24, min_count=5, window=5, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e7a39edb-fedb-45f8-9bd7-c5e380117582",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = nyt_data_fine.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "be0aa96c-5d43-4d75-9318-e57114c8b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_weights = {}\n",
    "for seed_cat in nyt_data_fine_seed:\n",
    "    for seed_word in nyt_data_fine_seed[seed_cat]:\n",
    "        if seed_word in model.wv:\n",
    "            try:\n",
    "                seed_weights[seed_cat] += model.wv[seed_word]\n",
    "            except:\n",
    "                seed_weights[seed_cat] = model.wv[seed_word]\n",
    "    seed_weights[seed_cat] = seed_weights[seed_cat] / len(nyt_data_fine_seed[seed_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f934c73d-83e8-454c-ae95-896ea3e84e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "doc_weights = []\n",
    "for sentence in words:\n",
    "    cnt = 0\n",
    "    doc_w = None\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            cnt += 1\n",
    "            if doc_w is None:\n",
    "                doc_w = copy(model.wv[word])\n",
    "            else:\n",
    "                doc_w += model.wv[word]\n",
    "    doc_weights.append(doc_w / cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f1188f9b-879c-46d5-b568-b16e9ce16bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for doc, val in enumerate(doc_weights):\n",
    "    sim = -10\n",
    "    pred = 'N/A'\n",
    "    for seed, seed_val in seed_weights.items():\n",
    "        currSim = 1 - spatial.distance.cosine(val, seed_val)\n",
    "        #print(currSim, seed)\n",
    "        if currSim > sim:\n",
    "            #print(sim, seed)\n",
    "            sim = currSim\n",
    "            pred = seed\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03379fa8-89e0-4d15-a345-b1de6e177f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_size = 0\n",
    "for seed_cat in nyt_data_fine_seed:\n",
    "    for seed_word in nyt_data_fine_seed[seed_cat]:\n",
    "        seed_size+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "021cce5b-4671-4de8-a2d0-25ff0632048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds[:len(doc_weights)-seed_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a624a3ff-cd8d-4500-bfa4-a89c994a821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = nyt_data_fine.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "48bcf3ae-31fe-4473-853a-7c4266807bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43225850625819234"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "43b4286e-e476-4ca9-8f0e-1a44f66eef86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7139758827101588"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, preds, average='micro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
